{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score\n",
    "import ecg_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.compat.v2' has no attribute '__internal__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_44350/1277975374.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./automatic-ecg-diagnosis/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# sys.path.append('./source/')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/scratch/tfg_luis_2223/automatic-ecg-diagnosis-private/automatic-ecg-diagnosis/predict.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mECGSequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \"\"\"\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequential\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/keras/models/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFunctional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequential\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtensor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayout_map\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlayout_map_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbase_layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/keras/backend.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistribute_coordinator_utils\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/keras/backend_config.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mkeras_export\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"keras.backend.epsilon\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_dispatch_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \"\"\"Returns the value of the fuzz factor used in numeric expressions.\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow.compat.v2' has no attribute '__internal__'"
     ]
    }
   ],
   "source": [
    "#Lanzar desde la carpeta LightX3ECGPrivate\n",
    "import sys\n",
    "sys.path.append('./automatic-ecg-diagnosis/')\n",
    "# sys.path.append('./source/')\n",
    "import predict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'automatic-ecg-diagnosis'...\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/antonior92/automatic-ecg-diagnosis.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.11.0-cp37-cp37m-win_amd64.whl (1.9 kB)\n",
      "Collecting tensorflow-intel==2.11.0; platform_system == \"Windows\"\n",
      "  Downloading tensorflow_intel-2.11.0-cp37-cp37m-win_amd64.whl (266.3 MB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-16.0.0-py2.py3-none-win_amd64.whl (24.4 MB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.54.0-cp37-cp37m-win_amd64.whl (4.1 MB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\quin-\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow) (4.5.0)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting tensorflow-estimator<2.12,>=2.11.0\n",
      "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting wrapt>=1.11.0\n",
      "  Downloading wrapt-1.15.0-cp37-cp37m-win_amd64.whl (35 kB)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\quin-\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow) (3.8.0)\n",
      "Collecting tensorboard<2.12,>=2.11\n",
      "  Downloading tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n",
      "Collecting protobuf<3.20,>=3.9.2\n",
      "  Downloading protobuf-3.19.6-cp37-cp37m-win_amd64.whl (896 kB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\quin-\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow) (1.21.6)\n",
      "Requirement already satisfied: setuptools in c:\\program files (x86)\\microsoft visual studio\\shared\\python37_64\\lib\\site-packages (from tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow) (47.1.0)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1; platform_machine != \"arm64\" or platform_system != \"Darwin\"\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp37-cp37m-win_amd64.whl (1.5 MB)\n",
      "Collecting keras<2.12,>=2.11.0\n",
      "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\quin-\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow) (23.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\quin-\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow) (1.16.0)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting flatbuffers>=2.0\n",
      "  Downloading flatbuffers-23.3.3-py2.py3-none-any.whl (26 kB)\n",
      "Collecting wheel<1.0,>=0.23.0\n",
      "  Downloading wheel-0.40.0-py3-none-any.whl (64 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Downloading Werkzeug-2.2.3-py3-none-any.whl (233 kB)\n",
      "Collecting requests<3,>=2.21.0\n",
      "  Downloading requests-2.29.0-py3-none-any.whl (62 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.4.3-py3-none-any.whl (93 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.17.3-py2.py3-none-any.whl (178 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting MarkupSafe>=2.1.1\n",
      "  Downloading MarkupSafe-2.1.2-cp37-cp37m-win_amd64.whl (16 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.15-py2.py3-none-any.whl (140 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Downloading certifi-2022.12.7-py3-none-any.whl (155 kB)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.1.0-cp37-cp37m-win_amd64.whl (94 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Downloading idna-3.4-py3-none-any.whl (61 kB)\n",
      "Collecting importlib-metadata>=4.4; python_version < \"3.10\"\n",
      "  Downloading importlib_metadata-6.6.0-py3-none-any.whl (22 kB)\n",
      "Collecting rsa<5,>=3.1.4; python_version >= \"3.6\"\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.3.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.15.0-py3-none-any.whl (6.8 kB)\n",
      "Collecting pyasn1>=0.1.3\n",
      "  Downloading pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
      "Installing collected packages: absl-py, libclang, grpcio, opt-einsum, tensorflow-estimator, wheel, astunparse, wrapt, urllib3, certifi, charset-normalizer, idna, requests, oauthlib, requests-oauthlib, pyasn1, rsa, pyasn1-modules, cachetools, google-auth, google-auth-oauthlib, MarkupSafe, werkzeug, zipp, importlib-metadata, markdown, tensorboard-data-server, tensorboard-plugin-wit, protobuf, tensorboard, termcolor, tensorflow-io-gcs-filesystem, keras, gast, google-pasta, flatbuffers, tensorflow-intel, tensorflow\n",
      "Successfully installed MarkupSafe-2.1.2 absl-py-1.4.0 astunparse-1.6.3 cachetools-5.3.0 certifi-2022.12.7 charset-normalizer-3.1.0 flatbuffers-23.3.3 gast-0.4.0 google-auth-2.17.3 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.54.0 idna-3.4 importlib-metadata-6.6.0 keras-2.11.0 libclang-16.0.0 markdown-3.4.3 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-3.19.6 pyasn1-0.5.0 pyasn1-modules-0.3.0 requests-2.29.0 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.11.2 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.11.0 tensorflow-estimator-2.11.0 tensorflow-intel-2.11.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.3.0 urllib3-1.26.15 werkzeug-2.2.3 wheel-0.40.0 wrapt-1.15.0 zipp-3.15.0\n"
     ]
    }
   ],
   "source": [
    "#Comando windows\n",
    "!py -m pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e:\\automatic-ecg-diagnosis-private\n"
     ]
    }
   ],
   "source": [
    "!cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e:\\automatic-ecg-diagnosis-private\\automatic-ecg-diagnosis\n"
     ]
    }
   ],
   "source": [
    "%cd automatic-ecg-diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"ls\" no se reconoce como un comando interno o externo,\n",
      "programa o archivo por lotes ejecutable.\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-05-02 18:21:58--  https://www.dropbox.com/s/p3vd3plcbu9sf1o/data.zip?dl=0\n",
      "Resolviendo www.dropbox.com (www.dropbox.com)... 162.125.68.18, 2620:100:6024:18::a27d:4412\n",
      "Conectando con www.dropbox.com (www.dropbox.com)[162.125.68.18]:443... conectado.\n",
      "Petición HTTP enviada, esperando respuesta... 302 Found\n",
      "Localización: /s/raw/p3vd3plcbu9sf1o/data.zip [siguiendo]\n",
      "--2023-05-02 18:21:58--  https://www.dropbox.com/s/raw/p3vd3plcbu9sf1o/data.zip\n",
      "Reutilizando la conexión con www.dropbox.com:443.\n",
      "Petición HTTP enviada, esperando respuesta... 302 Found\n",
      "Localización: https://uc776bd503b4554baf42e8e1444b.dl.dropboxusercontent.com/cd/0/inline/B7Qub56Dm4nFxk8XRoEMlBkzsCI3PaHncyWZKodICaR55uM9eMuYuoUZnH-9USPaOcJJ6qJM3mylVU6u86B3BR2k6jWUil7g29fotfKh0d6Kir86bKWE2Qd4ddmw2mvBrzpm5X-3y240SOomVSv8E0sCPCoBATC3cVbe2ZJF0MvPxg/file# [siguiendo]\n",
      "--2023-05-02 18:21:59--  https://uc776bd503b4554baf42e8e1444b.dl.dropboxusercontent.com/cd/0/inline/B7Qub56Dm4nFxk8XRoEMlBkzsCI3PaHncyWZKodICaR55uM9eMuYuoUZnH-9USPaOcJJ6qJM3mylVU6u86B3BR2k6jWUil7g29fotfKh0d6Kir86bKWE2Qd4ddmw2mvBrzpm5X-3y240SOomVSv8E0sCPCoBATC3cVbe2ZJF0MvPxg/file\n",
      "Resolviendo uc776bd503b4554baf42e8e1444b.dl.dropboxusercontent.com (uc776bd503b4554baf42e8e1444b.dl.dropboxusercontent.com)... 162.125.68.15, 2620:100:6024:15::a27d:440f\n",
      "Conectando con uc776bd503b4554baf42e8e1444b.dl.dropboxusercontent.com (uc776bd503b4554baf42e8e1444b.dl.dropboxusercontent.com)[162.125.68.15]:443... conectado.\n",
      "Petición HTTP enviada, esperando respuesta... 302 Found\n",
      "Localización: /cd/0/inline2/B7TlNlmhr_7DLsokkskHEbXDmj2joLye1vHoseDlc5iOk7w-zcX5NbLBMXSsO9sgn2Ek-sXWrPhxIVdNVm2LEc3z13ffoJcFlUmUWmV-fi3CXOuFbzbp_zwhIubxjeQpa2JkfutdPOfmzU_6BhUyrYlOUvFAaw4cXZR0bdQVnW9lgDEESn6I6dBaaXH8gw9r7eD98jH8qRgnRszAYdUHVRBniRoRrm81HTv8Eu1CAK8HtglyJzN7UhKl2banQk-l47tl6wSle5eZVFwcGd3rcjLQaFaGZ8ZnUNVBs4HdwhwV6wuKcps-h6m3H07TMRBD-7cUBD1qmfRWS1HiADDiMamkH8LhCPMcNMpEK6c26eRl-0YdLdv9VskS-ooecanIB2PMhgRJV36-Rxds8oTwtwIhzeChexBp4qn0DfQ9sDgwog/file [siguiendo]\n",
      "--2023-05-02 18:21:59--  https://uc776bd503b4554baf42e8e1444b.dl.dropboxusercontent.com/cd/0/inline2/B7TlNlmhr_7DLsokkskHEbXDmj2joLye1vHoseDlc5iOk7w-zcX5NbLBMXSsO9sgn2Ek-sXWrPhxIVdNVm2LEc3z13ffoJcFlUmUWmV-fi3CXOuFbzbp_zwhIubxjeQpa2JkfutdPOfmzU_6BhUyrYlOUvFAaw4cXZR0bdQVnW9lgDEESn6I6dBaaXH8gw9r7eD98jH8qRgnRszAYdUHVRBniRoRrm81HTv8Eu1CAK8HtglyJzN7UhKl2banQk-l47tl6wSle5eZVFwcGd3rcjLQaFaGZ8ZnUNVBs4HdwhwV6wuKcps-h6m3H07TMRBD-7cUBD1qmfRWS1HiADDiMamkH8LhCPMcNMpEK6c26eRl-0YdLdv9VskS-ooecanIB2PMhgRJV36-Rxds8oTwtwIhzeChexBp4qn0DfQ9sDgwog/file\n",
      "Reutilizando la conexión con uc776bd503b4554baf42e8e1444b.dl.dropboxusercontent.com:443.\n",
      "Petición HTTP enviada, esperando respuesta... 200 OK\n",
      "Longitud: 218189452 (208M) [application/zip]\n",
      "Grabando a: “data.zip”\n",
      "\n",
      "data.zip            100%[===================>] 208,08M  9,69MB/s    en 21s     \n",
      "\n",
      "2023-05-02 18:22:21 (9,72 MB/s) - “data.zip” guardado [218189452/218189452]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://www.dropbox.com/s/p3vd3plcbu9sf1o/data.zip?dl=0 -O data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  data.zip\n",
      "  inflating: data/ecg_tracings.hdf5  \n",
      "replace data/README.md? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n"
     ]
    }
   ],
   "source": [
    "!unzip data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tensorflow\n",
      "Version: 1.14.0\n",
      "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
      "Home-page: https://www.tensorflow.org/\n",
      "Author: Google Inc.\n",
      "Author-email: packages@tensorflow.org\n",
      "License: Apache 2.0\n",
      "Location: /home/tfg_luis_2223/.local/lib/python3.7/site-packages\n",
      "Requires: google-pasta, astor, gast, keras-preprocessing, six, protobuf, wheel, keras-applications, absl-py, tensorboard, wrapt, grpcio, numpy, termcolor, tensorflow-estimator\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip3 show tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python: can't open file 'install': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!python install -U pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# installing zipimport hook\n",
      "import zipimport # builtin\n",
      "# installed zipimport hook\n",
      "# /usr/lib/python2.7/site.pyc matches /usr/lib/python2.7/site.py\n",
      "import site # precompiled from /usr/lib/python2.7/site.pyc\n",
      "# /usr/lib/python2.7/os.pyc matches /usr/lib/python2.7/os.py\n",
      "import os # precompiled from /usr/lib/python2.7/os.pyc\n",
      "import errno # builtin\n",
      "import posix # builtin\n",
      "# /usr/lib/python2.7/posixpath.pyc matches /usr/lib/python2.7/posixpath.py\n",
      "import posixpath # precompiled from /usr/lib/python2.7/posixpath.pyc\n",
      "# /usr/lib/python2.7/stat.pyc matches /usr/lib/python2.7/stat.py\n",
      "import stat # precompiled from /usr/lib/python2.7/stat.pyc\n",
      "# /usr/lib/python2.7/genericpath.pyc matches /usr/lib/python2.7/genericpath.py\n",
      "import genericpath # precompiled from /usr/lib/python2.7/genericpath.pyc\n",
      "# /usr/lib/python2.7/warnings.pyc matches /usr/lib/python2.7/warnings.py\n",
      "import warnings # precompiled from /usr/lib/python2.7/warnings.pyc\n",
      "# /usr/lib/python2.7/linecache.pyc matches /usr/lib/python2.7/linecache.py\n",
      "import linecache # precompiled from /usr/lib/python2.7/linecache.pyc\n",
      "# /usr/lib/python2.7/types.pyc matches /usr/lib/python2.7/types.py\n",
      "import types # precompiled from /usr/lib/python2.7/types.pyc\n",
      "# /usr/lib/python2.7/UserDict.pyc matches /usr/lib/python2.7/UserDict.py\n",
      "import UserDict # precompiled from /usr/lib/python2.7/UserDict.pyc\n",
      "# /usr/lib/python2.7/_abcoll.pyc matches /usr/lib/python2.7/_abcoll.py\n",
      "import _abcoll # precompiled from /usr/lib/python2.7/_abcoll.pyc\n",
      "# /usr/lib/python2.7/abc.pyc matches /usr/lib/python2.7/abc.py\n",
      "import abc # precompiled from /usr/lib/python2.7/abc.pyc\n",
      "# /usr/lib/python2.7/_weakrefset.pyc matches /usr/lib/python2.7/_weakrefset.py\n",
      "import _weakrefset # precompiled from /usr/lib/python2.7/_weakrefset.pyc\n",
      "import _weakref # builtin\n",
      "# /usr/lib/python2.7/copy_reg.pyc matches /usr/lib/python2.7/copy_reg.py\n",
      "import copy_reg # precompiled from /usr/lib/python2.7/copy_reg.pyc\n",
      "# /usr/lib/python2.7/traceback.pyc matches /usr/lib/python2.7/traceback.py\n",
      "import traceback # precompiled from /usr/lib/python2.7/traceback.pyc\n",
      "# /usr/lib/python2.7/sysconfig.pyc matches /usr/lib/python2.7/sysconfig.py\n",
      "import sysconfig # precompiled from /usr/lib/python2.7/sysconfig.pyc\n",
      "# /usr/lib/python2.7/re.pyc matches /usr/lib/python2.7/re.py\n",
      "import re # precompiled from /usr/lib/python2.7/re.pyc\n",
      "# /usr/lib/python2.7/sre_compile.pyc matches /usr/lib/python2.7/sre_compile.py\n",
      "import sre_compile # precompiled from /usr/lib/python2.7/sre_compile.pyc\n",
      "import _sre # builtin\n",
      "# /usr/lib/python2.7/sre_parse.pyc matches /usr/lib/python2.7/sre_parse.py\n",
      "import sre_parse # precompiled from /usr/lib/python2.7/sre_parse.pyc\n",
      "# /usr/lib/python2.7/sre_constants.pyc matches /usr/lib/python2.7/sre_constants.py\n",
      "import sre_constants # precompiled from /usr/lib/python2.7/sre_constants.pyc\n",
      "import _locale # builtin\n",
      "# /usr/lib/python2.7/_sysconfigdata.pyc matches /usr/lib/python2.7/_sysconfigdata.py\n",
      "import _sysconfigdata # precompiled from /usr/lib/python2.7/_sysconfigdata.pyc\n",
      "# /usr/lib/python2.7/plat-x86_64-linux-gnu/_sysconfigdata_nd.pyc matches /usr/lib/python2.7/plat-x86_64-linux-gnu/_sysconfigdata_nd.py\n",
      "import _sysconfigdata_nd # precompiled from /usr/lib/python2.7/plat-x86_64-linux-gnu/_sysconfigdata_nd.pyc\n",
      "# /usr/lib/python2.7/sitecustomize.pyc matches /usr/lib/python2.7/sitecustomize.py\n",
      "import sitecustomize # precompiled from /usr/lib/python2.7/sitecustomize.pyc\n",
      "import encodings # directory /usr/lib/python2.7/encodings\n",
      "# /usr/lib/python2.7/encodings/__init__.pyc matches /usr/lib/python2.7/encodings/__init__.py\n",
      "import encodings # precompiled from /usr/lib/python2.7/encodings/__init__.pyc\n",
      "# /usr/lib/python2.7/codecs.pyc matches /usr/lib/python2.7/codecs.py\n",
      "import codecs # precompiled from /usr/lib/python2.7/codecs.pyc\n",
      "import _codecs # builtin\n",
      "# /usr/lib/python2.7/encodings/aliases.pyc matches /usr/lib/python2.7/encodings/aliases.py\n",
      "import encodings.aliases # precompiled from /usr/lib/python2.7/encodings/aliases.pyc\n",
      "# /usr/lib/python2.7/encodings/utf_8.pyc matches /usr/lib/python2.7/encodings/utf_8.py\n",
      "import encodings.utf_8 # precompiled from /usr/lib/python2.7/encodings/utf_8.pyc\n",
      "Python 2.7.16 (default, Oct 10 2019, 22:02:15) \n",
      "[GCC 8.3.0] on linux2\n",
      "Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n",
      "dlopen(\"/usr/lib/python2.7/lib-dynload/readline.x86_64-linux-gnu.so\", 2);\n",
      "import readline # dynamically loaded from /usr/lib/python2.7/lib-dynload/readline.x86_64-linux-gnu.so\n",
      ">>> \n",
      "Traceback (most recent call last):\n",
      "  File \"<stdin>\", line 1, in <module>\n",
      "KeyboardInterrupt\n",
      ">>> "
     ]
    }
   ],
   "source": [
    "!python -v"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## crear hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data/data2.hdf5'\n",
    "f = h5py.File(filename, 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'CasosNumpy'\n",
    "train = pd.read_csv(\"data/annotations/train.csv\")\n",
    "val = pd.read_csv(\"data/annotations/val.csv\")\n",
    "df = pd.concat([train,val],ignore_index=True,)\n",
    "group_name = 'tracings'\n",
    "shape = (len(df['id'].values),4096,12)\n",
    "dset = f.create_dataset(group_name,shape=shape)\n",
    "\n",
    "count = 0\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if(file_name[:5] in df['id'].values):\n",
    "        if file_name.endswith('.npy'):\n",
    "            # Cargar el archivo numpy\n",
    "            arr = np.load(os.path.join(folder_path, file_name))[:,:4096]\n",
    "            if arr.shape != (12, 4096):\n",
    "                new_arr = np.zeros((12, 4096))\n",
    "                new_arr[:arr.shape[0], :arr.shape[1]] = arr\n",
    "                arr = new_arr\n",
    "            #arr = tf.convert_to_tensor(arr, dtype=tf.float32)\n",
    "            dset[count, :, :] = arr.transpose()\n",
    "            count+=1\n",
    "            \n",
    "# Guardar el arreglo numpy en el grupo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6877\n"
     ]
    }
   ],
   "source": [
    "print(len(f[group_name]))\n",
    "f.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modificar val.csv a como lo tiene antonio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      label_0  label_1  label_2  label_3  label_4  label_5  label_6  label_7   \n",
      "0           0        0        0        0        1        0        0        0  \\\n",
      "1           1        0        0        0        0        0        0        0   \n",
      "2           0        1        0        0        0        0        0        0   \n",
      "3           0        1        0        0        0        0        0        0   \n",
      "4           0        0        0        0        0        0        1        0   \n",
      "...       ...      ...      ...      ...      ...      ...      ...      ...   \n",
      "6872        0        0        1        0        0        0        0        0   \n",
      "6873        0        0        0        0        0        0        0        1   \n",
      "6874        0        0        0        1        0        0        0        0   \n",
      "6875        0        1        0        0        0        0        0        0   \n",
      "6876        0        0        0        0        0        0        1        0   \n",
      "\n",
      "      label_8  \n",
      "0           0  \n",
      "1           0  \n",
      "2           0  \n",
      "3           0  \n",
      "4           0  \n",
      "...       ...  \n",
      "6872        0  \n",
      "6873        0  \n",
      "6874        0  \n",
      "6875        0  \n",
      "6876        0  \n",
      "\n",
      "[6877 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "val = pd.read_csv(\"data/annotations/val.csv\")\n",
    "#val = val.drop(['id','age','sex','r_count','length'],axis=1)\n",
    "\n",
    "train = pd.read_csv(\"data/annotations/train.csv\")\n",
    "#print(val)\n",
    "#print(train)\n",
    "final = pd.concat([train,val],ignore_index=True)\n",
    "final = final.sort_values('id',)\n",
    "final = final.reset_index()\n",
    "final = final.drop(['index','id','age','sex','r_count','length'],axis=1)\n",
    "\n",
    "print(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv(\"data/annotations/train_CPSC.csv\",)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to open file (unable to open file: name = 'datasets/pred.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15220\\1952910778.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m\"datasets/pred.hdf5\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tracings'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[0;32m    565\u001b[0m                                  \u001b[0mfs_persist\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfs_persist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfs_threshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfs_threshold\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m                                  fs_page_size=fs_page_size)\n\u001b[1;32m--> 567\u001b[1;33m                 \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    568\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    229\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mflags\u001b[0m \u001b[1;33m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 231\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    232\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'r+'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to open file (unable to open file: name = 'datasets/pred.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "args= \"datasets/pred.hdf5\"\n",
    "with h5py.File(args, \"r\") as f:\n",
    "    x = np.array(f['tracings'])\n",
    "\n",
    "np.size(x[1])\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Object arrays cannot be loaded when allow_pickle=False",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11100\\1094027530.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnpy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./history.npy\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mnpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[0;32m    439\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m                 return format.read_array(fid, allow_pickle=allow_pickle,\n\u001b[1;32m--> 441\u001b[1;33m                                          pickle_kwargs=pickle_kwargs)\n\u001b[0m\u001b[0;32m    442\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m             \u001b[1;31m# Try a pickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\lib\\format.py\u001b[0m in \u001b[0;36mread_array\u001b[1;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[0;32m    741\u001b[0m         \u001b[1;31m# The array contained Python objects. We need to unpickle the data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    742\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 743\u001b[1;33m             raise ValueError(\"Object arrays cannot be loaded when \"\n\u001b[0m\u001b[0;32m    744\u001b[0m                              \"allow_pickle=False\")\n\u001b[0;32m    745\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpickle_kwargs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Object arrays cannot be loaded when allow_pickle=False"
     ]
    }
   ],
   "source": [
    "npy = np.load(\"./history.npy\")\n",
    "npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ecgPlot(data,sample, factor = 1):\n",
    "    data = data* factor\n",
    "    print(data.shape)\n",
    "    #print(data)\n",
    "    xml_leads = ['DI', 'DII', 'DIII', 'AVR', 'AVL', 'AVF', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6']\n",
    "    ecg_plot.plot(data.T, sample_rate= sample,lead_index=xml_leads, title=f\"{filename}\")\n",
    "    ecg_plot.save_as_png(\"ecg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './automatic-ecg-diagnosis/data/train.hdf5'\n",
    "f = h5py.File(filename, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4096, 12)\n"
     ]
    }
   ],
   "source": [
    "ecgPlot(f['tracings'][1],400)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1/54 [..............................] - ETA: 7:01 - loss: 303.8179\n",
      " 2/54 [>.............................] - ETA: 3:25 - loss: -105.0874\n",
      " 3/54 [>.............................] - ETA: 3:26 - loss: -566.0938\n",
      " 4/54 [=>............................] - ETA: 3:27 - loss: -557.0286\n",
      " 5/54 [=>............................] - ETA: 3:19 - loss: -658.8395\n",
      " 6/54 [==>...........................] - ETA: 3:13 - loss: -756.3751\n",
      " 7/54 [==>...........................] - ETA: 3:07 - loss: -996.9410\n",
      " 8/54 [===>..........................] - ETA: 3:01 - loss: -894.8804\n",
      " 9/54 [====>.........................] - ETA: 2:56 - loss: -1448.4785\n",
      "10/54 [====>.........................] - ETA: 2:51 - loss: -1912.1560\n",
      "11/54 [=====>........................] - ETA: 2:47 - loss: -2434.7654\n",
      "12/54 [=====>........................] - ETA: 2:43 - loss: -2843.9207\n",
      "13/54 [======>.......................] - ETA: 2:38 - loss: -2634.6392\n",
      "14/54 [======>.......................] - ETA: 2:34 - loss: -3119.2732\n",
      "15/54 [=======>......................] - ETA: 2:30 - loss: -3532.4114\n",
      "16/54 [=======>......................] - ETA: 2:27 - loss: -3602.0122\n",
      "17/54 [========>.....................] - ETA: 2:24 - loss: -3658.9766\n",
      "18/54 [=========>....................] - ETA: 2:20 - loss: -3907.0508\n",
      "19/54 [=========>....................] - ETA: 2:16 - loss: -4065.0645\n",
      "20/54 [==========>...................] - ETA: 2:12 - loss: -4594.5459\n",
      "21/54 [==========>...................] - ETA: 2:09 - loss: -5051.1040\n",
      "22/54 [===========>..................] - ETA: 2:09 - loss: -5062.6260\n",
      "23/54 [===========>..................] - ETA: 2:10 - loss: -5388.3960\n",
      "24/54 [============>.................] - ETA: 2:11 - loss: -5631.5454\n",
      "25/54 [============>.................] - ETA: 2:11 - loss: -5699.2788\n",
      "26/54 [=============>................] - ETA: 2:11 - loss: -5564.2651\n",
      "27/54 [==============>...............] - ETA: 2:10 - loss: -5759.5308\n",
      "28/54 [==============>...............] - ETA: 2:08 - loss: -5748.0503\n",
      "29/54 [===============>..............] - ETA: 2:05 - loss: -6420.4136\n",
      "30/54 [===============>..............] - ETA: 2:03 - loss: -7053.8452\n",
      "31/54 [================>.............] - ETA: 1:59 - loss: -7567.7397\n",
      "32/54 [================>.............] - ETA: 1:54 - loss: -8114.2642\n",
      "33/54 [=================>............] - ETA: 1:50 - loss: -7911.8018\n",
      "34/54 [=================>............] - ETA: 1:47 - loss: -8305.8994\n",
      "35/54 [==================>...........] - ETA: 1:43 - loss: -8184.8115\n",
      "36/54 [===================>..........] - ETA: 1:39 - loss: -8457.3457\n",
      "37/54 [===================>..........] - ETA: 1:34 - loss: -8363.0625\n",
      "38/54 [====================>.........] - ETA: 1:29 - loss: -8836.8184\n",
      "39/54 [====================>.........] - ETA: 1:25 - loss: -9140.3643\n",
      "40/54 [=====================>........] - ETA: 1:20 - loss: -9062.5801\n",
      "41/54 [=====================>........] - ETA: 1:14 - loss: -8938.6172\n",
      "42/54 [======================>.......] - ETA: 1:09 - loss: -9467.6133\n",
      "43/54 [======================>.......] - ETA: 1:04 - loss: -10006.7139\n",
      "44/54 [=======================>......] - ETA: 58s - loss: -10554.5898 \n",
      "45/54 [========================>.....] - ETA: 53s - loss: -11114.1963\n",
      "46/54 [========================>.....] - ETA: 47s - loss: -11165.8057\n",
      "47/54 [=========================>....] - ETA: 41s - loss: -11834.7646\n",
      "48/54 [=========================>....] - ETA: 35s - loss: -11900.3369\n",
      "49/54 [==========================>...] - ETA: 30s - loss: -12114.6689\n",
      "50/54 [==========================>...] - ETA: 24s - loss: -12041.5332\n",
      "51/54 [===========================>..] - ETA: 18s - loss: -12153.2109\n",
      "52/54 [===========================>..] - ETA: 12s - loss: -12735.0869\n",
      "53/54 [============================>.] - ETA: 6s - loss: -12969.7051 \n",
      "54/54 [==============================] - ETA: 0s - loss: -12790.8604\n",
      "54/54 [==============================] - 379s 7s/step - loss: -12790.8604 - val_loss: -69358.4297 - lr: 0.0010\n",
      "\n",
      " 1/86 [..............................] - ETA: 27:07 - loss: -75.8217\n",
      " 2/86 [..............................] - ETA: 10:42 - loss: -242.6133\n",
      " 3/86 [>.............................] - ETA: 10:55 - loss: -656.2640\n",
      " 4/86 [>.............................] - ETA: 11:04 - loss: -1184.1731\n",
      " 5/86 [>.............................] - ETA: 10:52 - loss: -1725.5902\n",
      " 6/86 [=>............................] - ETA: 10:54 - loss: -2421.6960\n",
      " 7/86 [=>............................] - ETA: 10:40 - loss: -3189.7778\n",
      " 8/86 [=>............................] - ETA: 10:24 - loss: -3976.0098\n",
      " 9/86 [==>...........................] - ETA: 10:13 - loss: -4344.9434\n",
      "10/86 [==>...........................] - ETA: 10:02 - loss: -4388.9771\n",
      "11/86 [==>...........................] - ETA: 9:51 - loss: -4522.7109 \n",
      "12/86 [===>..........................] - ETA: 9:48 - loss: -5062.8984\n",
      "13/86 [===>..........................] - ETA: 9:41 - loss: -6433.5581\n",
      "14/86 [===>..........................] - ETA: 9:30 - loss: -6099.7607\n",
      "15/86 [====>.........................] - ETA: 9:21 - loss: -6120.5298\n",
      "16/86 [====>.........................] - ETA: 9:11 - loss: -6889.3008\n",
      "17/86 [====>.........................] - ETA: 9:03 - loss: -7573.3062\n",
      "18/86 [=====>........................] - ETA: 8:52 - loss: -7540.4365\n",
      "19/86 [=====>........................] - ETA: 8:43 - loss: -7480.5552\n",
      "20/86 [=====>........................] - ETA: 8:33 - loss: -7672.7710\n",
      "21/86 [======>.......................] - ETA: 8:24 - loss: -7550.5542\n",
      "22/86 [======>.......................] - ETA: 8:15 - loss: -7842.1426\n",
      "23/86 [=======>......................] - ETA: 8:05 - loss: -8882.3828\n",
      "24/86 [=======>......................] - ETA: 7:56 - loss: -9358.4404\n",
      "25/86 [=======>......................] - ETA: 7:47 - loss: -10323.5908\n",
      "26/86 [========>.....................] - ETA: 7:37 - loss: -10436.9336\n",
      "27/86 [========>.....................] - ETA: 7:29 - loss: -10678.9561\n",
      "28/86 [========>.....................] - ETA: 7:20 - loss: -11652.8506\n",
      "29/86 [=========>....................] - ETA: 7:12 - loss: -12639.2939\n",
      "30/86 [=========>....................] - ETA: 7:03 - loss: -12461.9277\n",
      "31/86 [=========>....................] - ETA: 6:55 - loss: -13666.9404\n",
      "32/86 [==========>...................] - ETA: 6:46 - loss: -14689.4414\n",
      "33/86 [==========>...................] - ETA: 6:37 - loss: -15357.5469\n",
      "34/86 [==========>...................] - ETA: 6:29 - loss: -16457.4746\n",
      "35/86 [===========>..................] - ETA: 6:22 - loss: -17485.6602\n",
      "36/86 [===========>..................] - ETA: 6:14 - loss: -17124.7871\n",
      "37/86 [===========>..................] - ETA: 6:07 - loss: -17112.7266\n",
      "38/86 [============>.................] - ETA: 6:00 - loss: -16690.7305\n",
      "39/86 [============>.................] - ETA: 5:49 - loss: -17853.2188\n",
      "40/86 [============>.................] - ETA: 5:37 - loss: -17416.0156\n",
      "41/86 [=============>................] - ETA: 5:26 - loss: -17875.8320\n",
      "42/86 [=============>................] - ETA: 5:15 - loss: -18121.0859\n",
      "43/86 [==============>...............] - ETA: 5:05 - loss: -18534.0645\n",
      "44/86 [==============>...............] - ETA: 4:54 - loss: -19308.0098\n",
      "45/86 [==============>...............] - ETA: 4:44 - loss: -19301.7676\n",
      "46/86 [===============>..............] - ETA: 4:34 - loss: -20257.2031\n",
      "47/86 [===============>..............] - ETA: 4:25 - loss: -20341.6738\n",
      "48/86 [===============>..............] - ETA: 4:16 - loss: -21249.7402\n",
      "49/86 [================>.............] - ETA: 4:07 - loss: -21951.8828\n",
      "50/86 [================>.............] - ETA: 3:58 - loss: -22517.7070\n",
      "51/86 [================>.............] - ETA: 3:49 - loss: -23135.9824\n",
      "52/86 [=================>............] - ETA: 3:41 - loss: -23247.2109\n",
      "53/86 [=================>............] - ETA: 3:32 - loss: -23661.8887\n",
      "54/86 [=================>............] - ETA: 3:24 - loss: -23476.5664\n",
      "55/86 [==================>...........] - ETA: 3:16 - loss: -23584.2441\n",
      "56/86 [==================>...........] - ETA: 3:09 - loss: -23904.8262\n",
      "57/86 [==================>...........] - ETA: 3:01 - loss: -24189.4570\n",
      "58/86 [===================>..........] - ETA: 2:54 - loss: -24866.9121\n",
      "59/86 [===================>..........] - ETA: 2:46 - loss: -25911.7793\n",
      "60/86 [===================>..........] - ETA: 2:39 - loss: -26651.1055\n",
      "61/86 [====================>.........] - ETA: 2:32 - loss: -27649.3926\n",
      "62/86 [====================>.........] - ETA: 2:25 - loss: -28243.3965\n",
      "63/86 [====================>.........] - ETA: 2:18 - loss: -29009.7676\n",
      "64/86 [=====================>........] - ETA: 2:11 - loss: -28697.6426\n",
      "65/86 [=====================>........] - ETA: 2:05 - loss: -28624.7617\n",
      "66/86 [======================>.......] - ETA: 1:58 - loss: -29499.3438\n",
      "67/86 [======================>.......] - ETA: 1:52 - loss: -29822.1914\n",
      "68/86 [======================>.......] - ETA: 1:45 - loss: -29997.2109\n",
      "69/86 [=======================>......] - ETA: 1:39 - loss: -29873.2363\n",
      "70/86 [=======================>......] - ETA: 1:33 - loss: -31024.2207\n",
      "71/86 [=======================>......] - ETA: 1:27 - loss: -31221.1426\n",
      "72/86 [========================>.....] - ETA: 1:20 - loss: -32290.3965\n",
      "73/86 [========================>.....] - ETA: 1:14 - loss: -32824.8320\n",
      "74/86 [========================>.....] - ETA: 1:08 - loss: -33755.5000\n",
      "75/86 [=========================>....] - ETA: 1:02 - loss: -33371.3359\n",
      "76/86 [=========================>....] - ETA: 56s - loss: -33832.4219 \n",
      "77/86 [=========================>....] - ETA: 50s - loss: -33591.6836\n",
      "78/86 [==========================>...] - ETA: 45s - loss: -34100.7383\n",
      "79/86 [==========================>...] - ETA: 39s - loss: -33829.8984\n",
      "80/86 [==========================>...] - ETA: 33s - loss: -33681.5898\n",
      "81/86 [===========================>..] - ETA: 27s - loss: -34864.7930\n",
      "82/86 [===========================>..] - ETA: 22s - loss: -35093.3789\n",
      "83/86 [===========================>..] - ETA: 16s - loss: -34850.9531\n",
      "84/86 [============================>.] - ETA: 11s - loss: -35427.5664\n",
      "85/86 [============================>.] - ETA: 5s - loss: -35057.6289 \n",
      "86/86 [==============================] - ETA: 0s - loss: -34734.5156\n",
      "86/86 [==============================] - 505s 6s/step - loss: -34734.5156 - val_loss: -184735.9688 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "!py train.py ./data/data.hdf5 ./data/annotations/train_CPSC.csv --val_split 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: train.py [-h] [--val_split VAL_SPLIT] [--dataset_name DATASET_NAME]\n",
      "                path_to_hdf5 path_to_csv\n",
      "\n",
      "Train neural network.\n",
      "\n",
      "positional arguments:\n",
      "  path_to_hdf5          path to hdf5 file containing tracings\n",
      "  path_to_csv           path to csv file containing annotations\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  --val_split VAL_SPLIT\n",
      "                        number between 0 and 1 determining how much of the\n",
      "                        data is to be used for validation. The remaining is\n",
      "                        used for validation. Default: 0.02\n",
      "  --dataset_name DATASET_NAME\n",
      "                        name of the hdf5 dataset containing tracings\n"
     ]
    }
   ],
   "source": [
    "!py train.py -h"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  1/215 [..............................] - ETA: 2:58\n",
      "  2/215 [..............................] - ETA: 1:09\n",
      "  3/215 [..............................] - ETA: 1:08\n",
      "  4/215 [..............................] - ETA: 1:07\n",
      "  5/215 [..............................] - ETA: 1:07\n",
      "  6/215 [..............................] - ETA: 1:06\n",
      "  7/215 [..............................] - ETA: 1:06\n",
      "  8/215 [>.............................] - ETA: 1:05\n",
      "  9/215 [>.............................] - ETA: 1:05\n",
      " 10/215 [>.............................] - ETA: 1:05\n",
      " 11/215 [>.............................] - ETA: 1:05\n",
      " 12/215 [>.............................] - ETA: 1:04\n",
      " 13/215 [>.............................] - ETA: 1:04\n",
      " 14/215 [>.............................] - ETA: 1:04\n",
      " 15/215 [=>............................] - ETA: 1:03\n",
      " 16/215 [=>............................] - ETA: 1:03\n",
      " 17/215 [=>............................] - ETA: 1:03\n",
      " 18/215 [=>............................] - ETA: 1:03\n",
      " 19/215 [=>............................] - ETA: 1:02\n",
      " 20/215 [=>............................] - ETA: 1:02\n",
      " 21/215 [=>............................] - ETA: 1:02\n",
      " 22/215 [==>...........................] - ETA: 1:01\n",
      " 23/215 [==>...........................] - ETA: 1:01\n",
      " 24/215 [==>...........................] - ETA: 1:01\n",
      " 25/215 [==>...........................] - ETA: 1:01\n",
      " 26/215 [==>...........................] - ETA: 1:00\n",
      " 27/215 [==>...........................] - ETA: 1:00\n",
      " 28/215 [==>...........................] - ETA: 1:01\n",
      " 29/215 [===>..........................] - ETA: 1:00\n",
      " 30/215 [===>..........................] - ETA: 1:00\n",
      " 31/215 [===>..........................] - ETA: 1:00\n",
      " 32/215 [===>..........................] - ETA: 1:00\n",
      " 33/215 [===>..........................] - ETA: 59s \n",
      " 34/215 [===>..........................] - ETA: 59s\n",
      " 35/215 [===>..........................] - ETA: 59s\n",
      " 36/215 [====>.........................] - ETA: 58s\n",
      " 37/215 [====>.........................] - ETA: 58s\n",
      " 38/215 [====>.........................] - ETA: 58s\n",
      " 39/215 [====>.........................] - ETA: 57s\n",
      " 40/215 [====>.........................] - ETA: 57s\n",
      " 41/215 [====>.........................] - ETA: 57s\n",
      " 42/215 [====>.........................] - ETA: 56s\n",
      " 43/215 [=====>........................] - ETA: 56s\n",
      " 44/215 [=====>........................] - ETA: 55s\n",
      " 45/215 [=====>........................] - ETA: 55s\n",
      " 46/215 [=====>........................] - ETA: 55s\n",
      " 47/215 [=====>........................] - ETA: 54s\n",
      " 48/215 [=====>........................] - ETA: 54s\n",
      " 49/215 [=====>........................] - ETA: 54s\n",
      " 50/215 [=====>........................] - ETA: 53s\n",
      " 51/215 [======>.......................] - ETA: 53s\n",
      " 52/215 [======>.......................] - ETA: 53s\n",
      " 53/215 [======>.......................] - ETA: 52s\n",
      " 54/215 [======>.......................] - ETA: 52s\n",
      " 55/215 [======>.......................] - ETA: 52s\n",
      " 56/215 [======>.......................] - ETA: 51s\n",
      " 57/215 [======>.......................] - ETA: 51s\n",
      " 58/215 [=======>......................] - ETA: 51s\n",
      " 59/215 [=======>......................] - ETA: 50s\n",
      " 60/215 [=======>......................] - ETA: 50s\n",
      " 61/215 [=======>......................] - ETA: 50s\n",
      " 62/215 [=======>......................] - ETA: 49s\n",
      " 63/215 [=======>......................] - ETA: 49s\n",
      " 64/215 [=======>......................] - ETA: 49s\n",
      " 65/215 [========>.....................] - ETA: 48s\n",
      " 66/215 [========>.....................] - ETA: 48s\n",
      " 67/215 [========>.....................] - ETA: 48s\n",
      " 68/215 [========>.....................] - ETA: 47s\n",
      " 69/215 [========>.....................] - ETA: 47s\n",
      " 70/215 [========>.....................] - ETA: 47s\n",
      " 71/215 [========>.....................] - ETA: 46s\n",
      " 72/215 [=========>....................] - ETA: 46s\n",
      " 73/215 [=========>....................] - ETA: 46s\n",
      " 74/215 [=========>....................] - ETA: 45s\n",
      " 75/215 [=========>....................] - ETA: 45s\n",
      " 76/215 [=========>....................] - ETA: 45s\n",
      " 77/215 [=========>....................] - ETA: 44s\n",
      " 78/215 [=========>....................] - ETA: 44s\n",
      " 79/215 [==========>...................] - ETA: 44s\n",
      " 80/215 [==========>...................] - ETA: 43s\n",
      " 81/215 [==========>...................] - ETA: 43s\n",
      " 82/215 [==========>...................] - ETA: 43s\n",
      " 83/215 [==========>...................] - ETA: 42s\n",
      " 84/215 [==========>...................] - ETA: 42s\n",
      " 85/215 [==========>...................] - ETA: 42s\n",
      " 86/215 [===========>..................] - ETA: 41s\n",
      " 87/215 [===========>..................] - ETA: 41s\n",
      " 88/215 [===========>..................] - ETA: 41s\n",
      " 89/215 [===========>..................] - ETA: 40s\n",
      " 90/215 [===========>..................] - ETA: 40s\n",
      " 91/215 [===========>..................] - ETA: 40s\n",
      " 92/215 [===========>..................] - ETA: 39s\n",
      " 93/215 [===========>..................] - ETA: 39s\n",
      " 94/215 [============>.................] - ETA: 39s\n",
      " 95/215 [============>.................] - ETA: 39s\n",
      " 96/215 [============>.................] - ETA: 39s\n",
      " 97/215 [============>.................] - ETA: 38s\n",
      " 98/215 [============>.................] - ETA: 38s\n",
      " 99/215 [============>.................] - ETA: 38s\n",
      "100/215 [============>.................] - ETA: 38s\n",
      "101/215 [=============>................] - ETA: 37s\n",
      "102/215 [=============>................] - ETA: 37s\n",
      "103/215 [=============>................] - ETA: 37s\n",
      "104/215 [=============>................] - ETA: 37s\n",
      "105/215 [=============>................] - ETA: 37s\n",
      "106/215 [=============>................] - ETA: 36s\n",
      "107/215 [=============>................] - ETA: 36s\n",
      "108/215 [==============>...............] - ETA: 36s\n",
      "109/215 [==============>...............] - ETA: 36s\n",
      "110/215 [==============>...............] - ETA: 35s\n",
      "111/215 [==============>...............] - ETA: 35s\n",
      "112/215 [==============>...............] - ETA: 35s\n",
      "113/215 [==============>...............] - ETA: 34s\n",
      "114/215 [==============>...............] - ETA: 34s\n",
      "115/215 [===============>..............] - ETA: 34s\n",
      "116/215 [===============>..............] - ETA: 33s\n",
      "117/215 [===============>..............] - ETA: 33s\n",
      "118/215 [===============>..............] - ETA: 33s\n",
      "119/215 [===============>..............] - ETA: 32s\n",
      "120/215 [===============>..............] - ETA: 32s\n",
      "121/215 [===============>..............] - ETA: 32s\n",
      "122/215 [================>.............] - ETA: 31s\n",
      "123/215 [================>.............] - ETA: 31s\n",
      "124/215 [================>.............] - ETA: 31s\n",
      "125/215 [================>.............] - ETA: 30s\n",
      "126/215 [================>.............] - ETA: 30s\n",
      "127/215 [================>.............] - ETA: 30s\n",
      "128/215 [================>.............] - ETA: 29s\n",
      "129/215 [=================>............] - ETA: 29s\n",
      "130/215 [=================>............] - ETA: 29s\n",
      "131/215 [=================>............] - ETA: 28s\n",
      "132/215 [=================>............] - ETA: 28s\n",
      "133/215 [=================>............] - ETA: 28s\n",
      "134/215 [=================>............] - ETA: 27s\n",
      "135/215 [=================>............] - ETA: 27s\n",
      "136/215 [=================>............] - ETA: 27s\n",
      "137/215 [==================>...........] - ETA: 26s\n",
      "138/215 [==================>...........] - ETA: 26s\n",
      "139/215 [==================>...........] - ETA: 25s\n",
      "140/215 [==================>...........] - ETA: 25s\n",
      "141/215 [==================>...........] - ETA: 25s\n",
      "142/215 [==================>...........] - ETA: 24s\n",
      "143/215 [==================>...........] - ETA: 24s\n",
      "144/215 [===================>..........] - ETA: 24s\n",
      "145/215 [===================>..........] - ETA: 23s\n",
      "146/215 [===================>..........] - ETA: 23s\n",
      "147/215 [===================>..........] - ETA: 23s\n",
      "148/215 [===================>..........] - ETA: 22s\n",
      "149/215 [===================>..........] - ETA: 22s\n",
      "150/215 [===================>..........] - ETA: 22s\n",
      "151/215 [====================>.........] - ETA: 21s\n",
      "152/215 [====================>.........] - ETA: 21s\n",
      "153/215 [====================>.........] - ETA: 21s\n",
      "154/215 [====================>.........] - ETA: 20s\n",
      "155/215 [====================>.........] - ETA: 20s\n",
      "156/215 [====================>.........] - ETA: 20s\n",
      "157/215 [====================>.........] - ETA: 19s\n",
      "158/215 [=====================>........] - ETA: 19s\n",
      "159/215 [=====================>........] - ETA: 19s\n",
      "160/215 [=====================>........] - ETA: 18s\n",
      "161/215 [=====================>........] - ETA: 18s\n",
      "162/215 [=====================>........] - ETA: 18s\n",
      "163/215 [=====================>........] - ETA: 17s\n",
      "164/215 [=====================>........] - ETA: 17s\n",
      "165/215 [======================>.......] - ETA: 17s\n",
      "166/215 [======================>.......] - ETA: 16s\n",
      "167/215 [======================>.......] - ETA: 16s\n",
      "168/215 [======================>.......] - ETA: 16s\n",
      "169/215 [======================>.......] - ETA: 15s\n",
      "170/215 [======================>.......] - ETA: 15s\n",
      "171/215 [======================>.......] - ETA: 15s\n",
      "172/215 [=======================>......] - ETA: 14s\n",
      "173/215 [=======================>......] - ETA: 14s\n",
      "174/215 [=======================>......] - ETA: 14s\n",
      "175/215 [=======================>......] - ETA: 13s\n",
      "176/215 [=======================>......] - ETA: 13s\n",
      "177/215 [=======================>......] - ETA: 13s\n",
      "178/215 [=======================>......] - ETA: 12s\n",
      "179/215 [=======================>......] - ETA: 12s\n",
      "180/215 [========================>.....] - ETA: 12s\n",
      "181/215 [========================>.....] - ETA: 11s\n",
      "182/215 [========================>.....] - ETA: 11s\n",
      "183/215 [========================>.....] - ETA: 11s\n",
      "184/215 [========================>.....] - ETA: 10s\n",
      "185/215 [========================>.....] - ETA: 10s\n",
      "186/215 [========================>.....] - ETA: 9s \n",
      "187/215 [=========================>....] - ETA: 9s\n",
      "188/215 [=========================>....] - ETA: 9s\n",
      "189/215 [=========================>....] - ETA: 8s\n",
      "190/215 [=========================>....] - ETA: 8s\n",
      "191/215 [=========================>....] - ETA: 8s\n",
      "192/215 [=========================>....] - ETA: 7s\n",
      "193/215 [=========================>....] - ETA: 7s\n",
      "194/215 [==========================>...] - ETA: 7s\n",
      "195/215 [==========================>...] - ETA: 6s\n",
      "196/215 [==========================>...] - ETA: 6s\n",
      "197/215 [==========================>...] - ETA: 6s\n",
      "198/215 [==========================>...] - ETA: 5s\n",
      "199/215 [==========================>...] - ETA: 5s\n",
      "200/215 [==========================>...] - ETA: 5s\n",
      "201/215 [===========================>..] - ETA: 4s\n",
      "202/215 [===========================>..] - ETA: 4s\n",
      "203/215 [===========================>..] - ETA: 4s\n",
      "204/215 [===========================>..] - ETA: 3s\n",
      "205/215 [===========================>..] - ETA: 3s\n",
      "206/215 [===========================>..] - ETA: 3s\n",
      "207/215 [===========================>..] - ETA: 2s\n",
      "208/215 [============================>.] - ETA: 2s\n",
      "209/215 [============================>.] - ETA: 2s\n",
      "210/215 [============================>.] - ETA: 1s\n",
      "211/215 [============================>.] - ETA: 1s\n",
      "212/215 [============================>.] - ETA: 1s\n",
      "213/215 [============================>.] - ETA: 0s\n",
      "214/215 [============================>.] - ETA: 0s\n",
      "215/215 [==============================] - ETA: 0s\n",
      "215/215 [==============================] - 75s 344ms/step\n",
      "Output predictions saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-15 10:31:22.661074: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "PFOLDER=\"./dnn_predicts\"\n",
    "DFOLDER=\"./data\" #Nos hemos cambiado al directorio de automatic-ecg-diagnosis\n",
    "\n",
    "!python predict.py $DFOLDER/data.hdf5 final_model_.hdf5 --output_file $PFOLDER/train_val.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PFOLDER=\"./dnn_predicts\"\n",
    "DFOLDER=\"./data\" #Nos hemos cambiado al directorio de automatic-ecg-diagnosis\n",
    "\n",
    "!python predict.py $DFOLDER/ecg_tracings2.hdf5 model.hdf5 --output_file $PFOLDER/ecg_tracings.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1/1 [==============================] - ETA: 0s\n",
      "1/1 [==============================] - 1s 621ms/step\n",
      "Output predictions saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-15 10:40:05.019104: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "PFOLDER=\"./dnn_predicts\"\n",
    "DFOLDER=\"./data\" #Nos hemos cambiado al directorio de automatic-ecg-diagnosis\n",
    "\n",
    "!python predict.py $DFOLDER/pred.hdf5 final_model_.hdf5 --output_file $PFOLDER/pred.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: predict.py [-h] [--dataset_name DATASET_NAME]\n",
      "                  [--output_file OUTPUT_FILE] [-bs BS]\n",
      "                  path_to_hdf5 path_to_model\n",
      "\n",
      "Get performance on test set from hdf5\n",
      "\n",
      "positional arguments:\n",
      "  path_to_hdf5          path to hdf5 file containing tracings\n",
      "  path_to_model         file containing training model.\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  --dataset_name DATASET_NAME\n",
      "                        name of the hdf5 dataset containing tracings\n",
      "  --output_file OUTPUT_FILE\n",
      "                        output csv file.\n",
      "  -bs BS                Batch size.\n"
     ]
    }
   ],
   "source": [
    "!python predict.py -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.5101798e-03 1.6017100e-05 6.6078037e-01 5.1851600e-04 2.2911260e-07]\n",
      "[22  0  0  0  1  0  0]\n"
     ]
    }
   ],
   "source": [
    "pred = np.load('dnn_predicts/ecg_tracings.npy')\n",
    "csv = pd.read_csv('data/annotations/dnn.csv')\n",
    "pos = 22\n",
    "print(pred[pos,1:])\n",
    "print(csv.values[pos])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = np.load('dnn_predicts/model_pred.npy')\n",
    "pred[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.1813236e-01 2.8199967e-02 1.2204376e-01 5.4315905e-19 4.4130284e-06\n",
      " 2.0833155e-05 6.2848147e-07 7.4192864e-04 2.2872496e-06]\n",
      "[0 0 0 0 1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "pred = np.load('dnn_predicts/train_val.npy')\n",
    "csv = pd.read_csv('data/annotations/train_CPSC.csv')\n",
    "pos = 3\n",
    "print(pred[pos,1:])\n",
    "print(csv.values[pos,1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.20027375e-01 2.83536166e-02 1.21105045e-01 5.42684766e-19\n",
      " 4.58824525e-06 2.08452784e-05 6.21495985e-07 7.38178031e-04\n",
      " 2.34572985e-06]\n",
      "[65 0 0 0 0 1 0 0 0 0 0 12 5000]\n"
     ]
    }
   ],
   "source": [
    "pred = np.load('dnn_predicts/pred.npy')\n",
    "csv = pd.read_csv('data/annotations/pred.csv')\n",
    "pos = 10\n",
    "print(pred[pos,1:])\n",
    "print(csv.values[pos,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0      1      2      3      4      5      6      7      8\n",
      "Threshold  True  False  False  False  False  False  False  False  False\n",
      "Threshold  True  False  False  False  False  False  False  False  False\n",
      "Threshold  True  False  False  False  False  False  False  False  False\n",
      "Threshold  True  False  False  False  False  False  False  False  False\n",
      "Threshold  True  False  False  False  False  False  False  False  False\n",
      "...         ...    ...    ...    ...    ...    ...    ...    ...    ...\n",
      "Threshold  True  False  False  False  False  False  False  False  False\n",
      "Threshold  True  False  False  False  False  False  False  False  False\n",
      "Threshold  True  False  False  False  False  False  False  False  False\n",
      "Threshold  True  False  False  False  False  False  False  False  False\n",
      "Threshold  True  False  False  False  False  False  False  False  False\n",
      "\n",
      "[6877 rows x 9 columns]\n",
      "           0  1  2  3  4  5  6  7  8\n",
      "Threshold  1  0  0  0  0  0  0  0  0\n",
      "Threshold  1  0  0  0  0  0  0  0  0\n",
      "Threshold  1  0  0  0  0  0  0  0  0\n",
      "Threshold  1  0  0  0  0  0  0  0  0\n",
      "Threshold  1  0  0  0  0  0  0  0  0\n",
      "...       .. .. .. .. .. .. .. .. ..\n",
      "Threshold  1  0  0  0  0  0  0  0  0\n",
      "Threshold  1  0  0  0  0  0  0  0  0\n",
      "Threshold  1  0  0  0  0  0  0  0  0\n",
      "Threshold  1  0  0  0  0  0  0  0  0\n",
      "Threshold  1  0  0  0  0  0  0  0  0\n",
      "\n",
      "[6877 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "pred = np.load('dnn_predicts/train_val.npy')\n",
    "csv = pd.read_csv('data/annotations/train_CPSC.csv',)\n",
    "threshold = pd.read_csv('dnn_predicts/optimal_thresholds_best.csv')\n",
    "result = pd.DataFrame(data= [])\n",
    "\n",
    "for pos in range(len(pred)):\n",
    "    data = pd.DataFrame([pred[pos,1:] >= threshold['Threshold']])\n",
    "    result = pd.concat([result,data])\n",
    "\n",
    "result = result.replace({True:1,False:0})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0  1  2  3  4  5  6  7  8\n",
      "Threshold  1  0  0  0  0  0  0  0  0\n",
      "Threshold  1  0  0  0  0  0  0  0  0\n",
      "Threshold  1  0  0  0  0  0  0  0  0\n",
      "Threshold  1  0  0  0  0  0  0  0  0\n",
      "Threshold  1  0  0  0  0  0  0  0  0\n",
      "Threshold  1  0  0  0  0  0  0  0  0\n",
      "Threshold  1  0  0  0  0  0  0  0  0\n",
      "Threshold  1  0  0  0  0  0  0  0  0\n",
      "Threshold  1  0  0  0  0  0  0  0  0\n",
      "Threshold  1  0  0  0  0  0  0  0  0\n",
      "Threshold  1  0  0  0  0  0  0  0  0\n",
      "Threshold  1  0  0  0  0  0  0  0  0\n",
      "Threshold  1  0  0  0  0  0  0  0  0\n",
      "Threshold  1  0  0  0  0  0  0  0  0\n",
      "Threshold  1  0  0  0  0  0  0  0  0\n",
      "Threshold  1  0  0  0  0  0  0  0  0\n",
      "Threshold  1  0  0  0  0  0  0  0  0\n",
      "Threshold  1  0  0  0  0  0  0  0  0\n",
      "Threshold  1  0  0  0  0  0  0  0  0\n",
      "Threshold  1  0  0  0  0  0  0  0  0\n",
      "Threshold  1  0  0  0  0  0  0  0  0\n",
      "Threshold  1  0  0  0  0  0  0  0  0\n",
      "Threshold  1  0  0  0  0  0  0  0  0\n",
      "Threshold  1  0  0  0  0  0  0  0  0\n",
      "Threshold  1  0  0  0  0  0  0  0  0\n",
      "Threshold  1  0  0  0  0  0  0  0  0\n",
      "Threshold  1  0  0  0  0  0  0  0  0\n"
     ]
    }
   ],
   "source": [
    "pred = np.load('dnn_predicts/pred.npy')\n",
    "csv = pd.read_csv('data/annotations/pred.csv',)\n",
    "csv = csv.drop(columns=['age','sex','r_count','length'],axis=1)\n",
    "\n",
    "threshold = pd.read_csv('dnn_predicts/optimal_thresholds_best.csv')\n",
    "result = pd.DataFrame(data= [])\n",
    "\n",
    "for pos in range(len(pred)):\n",
    "    data = pd.DataFrame([pred[pos,1:] >= threshold['Threshold']])\n",
    "    result = pd.concat([result,data])\n",
    "\n",
    "result = result.replace({True:1,False:0})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv.values[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of unknown and multilabel-indicator targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m accuracy \u001b[39m=\u001b[39m accuracy_score(csv\u001b[39m.\u001b[39;49mvalues[:,\u001b[39m1\u001b[39;49m:],result\u001b[39m.\u001b[39;49mvalues)\n\u001b[0;32m      2\u001b[0m accuracy\n",
      "File \u001b[1;32mc:\\Users\\quin-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:192\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    187\u001b[0m validate_parameter_constraints(\n\u001b[0;32m    188\u001b[0m     parameter_constraints, params, caller_name\u001b[39m=\u001b[39mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\n\u001b[0;32m    189\u001b[0m )\n\u001b[0;32m    191\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 192\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    193\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    194\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    195\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    196\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    197\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    198\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[0;32m    199\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    200\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    201\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[0;32m    202\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\quin-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:221\u001b[0m, in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \n\u001b[0;32m    157\u001b[0m \u001b[39mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[39m0.5\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[39m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[1;32m--> 221\u001b[0m y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[0;32m    222\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    223\u001b[0m \u001b[39mif\u001b[39;00m y_type\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39mmultilabel\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\quin-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:95\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     92\u001b[0m     y_type \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[0;32m     94\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(y_type) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 95\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m     96\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mClassification metrics can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt handle a mix of \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m targets\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m     97\u001b[0m             type_true, type_pred\n\u001b[0;32m     98\u001b[0m         )\n\u001b[0;32m     99\u001b[0m     )\n\u001b[0;32m    101\u001b[0m \u001b[39m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    102\u001b[0m y_type \u001b[39m=\u001b[39m y_type\u001b[39m.\u001b[39mpop()\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of unknown and multilabel-indicator targets"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(csv.values[:,1:],result.values)\n",
    "accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
