{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.compat.v2' has no attribute '__internal__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_44350/1277975374.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./automatic-ecg-diagnosis/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# sys.path.append('./source/')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/scratch/tfg_luis_2223/automatic-ecg-diagnosis-private/automatic-ecg-diagnosis/predict.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mECGSequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \"\"\"\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequential\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/keras/models/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFunctional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequential\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtensor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayout_map\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlayout_map_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbase_layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/keras/backend.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistribute_coordinator_utils\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/keras/backend_config.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mkeras_export\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"keras.backend.epsilon\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_dispatch_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \"\"\"Returns the value of the fuzz factor used in numeric expressions.\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow.compat.v2' has no attribute '__internal__'"
     ]
    }
   ],
   "source": [
    "#Lanzar desde la carpeta LightX3ECGPrivate\n",
    "import sys\n",
    "sys.path.append('./automatic-ecg-diagnosis/')\n",
    "# sys.path.append('./source/')\n",
    "import predict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'automatic-ecg-diagnosis'...\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/antonior92/automatic-ecg-diagnosis.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.11.0-cp37-cp37m-win_amd64.whl (1.9 kB)\n",
      "Collecting tensorflow-intel==2.11.0; platform_system == \"Windows\"\n",
      "  Downloading tensorflow_intel-2.11.0-cp37-cp37m-win_amd64.whl (266.3 MB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-16.0.0-py2.py3-none-win_amd64.whl (24.4 MB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.54.0-cp37-cp37m-win_amd64.whl (4.1 MB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\quin-\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow) (4.5.0)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting tensorflow-estimator<2.12,>=2.11.0\n",
      "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting wrapt>=1.11.0\n",
      "  Downloading wrapt-1.15.0-cp37-cp37m-win_amd64.whl (35 kB)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\quin-\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow) (3.8.0)\n",
      "Collecting tensorboard<2.12,>=2.11\n",
      "  Downloading tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n",
      "Collecting protobuf<3.20,>=3.9.2\n",
      "  Downloading protobuf-3.19.6-cp37-cp37m-win_amd64.whl (896 kB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\quin-\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow) (1.21.6)\n",
      "Requirement already satisfied: setuptools in c:\\program files (x86)\\microsoft visual studio\\shared\\python37_64\\lib\\site-packages (from tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow) (47.1.0)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1; platform_machine != \"arm64\" or platform_system != \"Darwin\"\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp37-cp37m-win_amd64.whl (1.5 MB)\n",
      "Collecting keras<2.12,>=2.11.0\n",
      "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\quin-\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow) (23.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\quin-\\appdata\\roaming\\python\\python37\\site-packages (from tensorflow-intel==2.11.0; platform_system == \"Windows\"->tensorflow) (1.16.0)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting flatbuffers>=2.0\n",
      "  Downloading flatbuffers-23.3.3-py2.py3-none-any.whl (26 kB)\n",
      "Collecting wheel<1.0,>=0.23.0\n",
      "  Downloading wheel-0.40.0-py3-none-any.whl (64 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Downloading Werkzeug-2.2.3-py3-none-any.whl (233 kB)\n",
      "Collecting requests<3,>=2.21.0\n",
      "  Downloading requests-2.29.0-py3-none-any.whl (62 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.4.3-py3-none-any.whl (93 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.17.3-py2.py3-none-any.whl (178 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting MarkupSafe>=2.1.1\n",
      "  Downloading MarkupSafe-2.1.2-cp37-cp37m-win_amd64.whl (16 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.15-py2.py3-none-any.whl (140 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Downloading certifi-2022.12.7-py3-none-any.whl (155 kB)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.1.0-cp37-cp37m-win_amd64.whl (94 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Downloading idna-3.4-py3-none-any.whl (61 kB)\n",
      "Collecting importlib-metadata>=4.4; python_version < \"3.10\"\n",
      "  Downloading importlib_metadata-6.6.0-py3-none-any.whl (22 kB)\n",
      "Collecting rsa<5,>=3.1.4; python_version >= \"3.6\"\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.3.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.15.0-py3-none-any.whl (6.8 kB)\n",
      "Collecting pyasn1>=0.1.3\n",
      "  Downloading pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
      "Installing collected packages: absl-py, libclang, grpcio, opt-einsum, tensorflow-estimator, wheel, astunparse, wrapt, urllib3, certifi, charset-normalizer, idna, requests, oauthlib, requests-oauthlib, pyasn1, rsa, pyasn1-modules, cachetools, google-auth, google-auth-oauthlib, MarkupSafe, werkzeug, zipp, importlib-metadata, markdown, tensorboard-data-server, tensorboard-plugin-wit, protobuf, tensorboard, termcolor, tensorflow-io-gcs-filesystem, keras, gast, google-pasta, flatbuffers, tensorflow-intel, tensorflow\n",
      "Successfully installed MarkupSafe-2.1.2 absl-py-1.4.0 astunparse-1.6.3 cachetools-5.3.0 certifi-2022.12.7 charset-normalizer-3.1.0 flatbuffers-23.3.3 gast-0.4.0 google-auth-2.17.3 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.54.0 idna-3.4 importlib-metadata-6.6.0 keras-2.11.0 libclang-16.0.0 markdown-3.4.3 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-3.19.6 pyasn1-0.5.0 pyasn1-modules-0.3.0 requests-2.29.0 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.11.2 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.11.0 tensorflow-estimator-2.11.0 tensorflow-intel-2.11.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.3.0 urllib3-1.26.15 werkzeug-2.2.3 wheel-0.40.0 wrapt-1.15.0 zipp-3.15.0\n"
     ]
    }
   ],
   "source": [
    "#Comando windows\n",
    "!py -m pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e:\\automatic-ecg-diagnosis-private\n"
     ]
    }
   ],
   "source": [
    "!cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e:\\automatic-ecg-diagnosis-private\\automatic-ecg-diagnosis\n"
     ]
    }
   ],
   "source": [
    "%cd automatic-ecg-diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"ls\" no se reconoce como un comando interno o externo,\n",
      "programa o archivo por lotes ejecutable.\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-05-02 18:21:58--  https://www.dropbox.com/s/p3vd3plcbu9sf1o/data.zip?dl=0\n",
      "Resolviendo www.dropbox.com (www.dropbox.com)... 162.125.68.18, 2620:100:6024:18::a27d:4412\n",
      "Conectando con www.dropbox.com (www.dropbox.com)[162.125.68.18]:443... conectado.\n",
      "Petición HTTP enviada, esperando respuesta... 302 Found\n",
      "Localización: /s/raw/p3vd3plcbu9sf1o/data.zip [siguiendo]\n",
      "--2023-05-02 18:21:58--  https://www.dropbox.com/s/raw/p3vd3plcbu9sf1o/data.zip\n",
      "Reutilizando la conexión con www.dropbox.com:443.\n",
      "Petición HTTP enviada, esperando respuesta... 302 Found\n",
      "Localización: https://uc776bd503b4554baf42e8e1444b.dl.dropboxusercontent.com/cd/0/inline/B7Qub56Dm4nFxk8XRoEMlBkzsCI3PaHncyWZKodICaR55uM9eMuYuoUZnH-9USPaOcJJ6qJM3mylVU6u86B3BR2k6jWUil7g29fotfKh0d6Kir86bKWE2Qd4ddmw2mvBrzpm5X-3y240SOomVSv8E0sCPCoBATC3cVbe2ZJF0MvPxg/file# [siguiendo]\n",
      "--2023-05-02 18:21:59--  https://uc776bd503b4554baf42e8e1444b.dl.dropboxusercontent.com/cd/0/inline/B7Qub56Dm4nFxk8XRoEMlBkzsCI3PaHncyWZKodICaR55uM9eMuYuoUZnH-9USPaOcJJ6qJM3mylVU6u86B3BR2k6jWUil7g29fotfKh0d6Kir86bKWE2Qd4ddmw2mvBrzpm5X-3y240SOomVSv8E0sCPCoBATC3cVbe2ZJF0MvPxg/file\n",
      "Resolviendo uc776bd503b4554baf42e8e1444b.dl.dropboxusercontent.com (uc776bd503b4554baf42e8e1444b.dl.dropboxusercontent.com)... 162.125.68.15, 2620:100:6024:15::a27d:440f\n",
      "Conectando con uc776bd503b4554baf42e8e1444b.dl.dropboxusercontent.com (uc776bd503b4554baf42e8e1444b.dl.dropboxusercontent.com)[162.125.68.15]:443... conectado.\n",
      "Petición HTTP enviada, esperando respuesta... 302 Found\n",
      "Localización: /cd/0/inline2/B7TlNlmhr_7DLsokkskHEbXDmj2joLye1vHoseDlc5iOk7w-zcX5NbLBMXSsO9sgn2Ek-sXWrPhxIVdNVm2LEc3z13ffoJcFlUmUWmV-fi3CXOuFbzbp_zwhIubxjeQpa2JkfutdPOfmzU_6BhUyrYlOUvFAaw4cXZR0bdQVnW9lgDEESn6I6dBaaXH8gw9r7eD98jH8qRgnRszAYdUHVRBniRoRrm81HTv8Eu1CAK8HtglyJzN7UhKl2banQk-l47tl6wSle5eZVFwcGd3rcjLQaFaGZ8ZnUNVBs4HdwhwV6wuKcps-h6m3H07TMRBD-7cUBD1qmfRWS1HiADDiMamkH8LhCPMcNMpEK6c26eRl-0YdLdv9VskS-ooecanIB2PMhgRJV36-Rxds8oTwtwIhzeChexBp4qn0DfQ9sDgwog/file [siguiendo]\n",
      "--2023-05-02 18:21:59--  https://uc776bd503b4554baf42e8e1444b.dl.dropboxusercontent.com/cd/0/inline2/B7TlNlmhr_7DLsokkskHEbXDmj2joLye1vHoseDlc5iOk7w-zcX5NbLBMXSsO9sgn2Ek-sXWrPhxIVdNVm2LEc3z13ffoJcFlUmUWmV-fi3CXOuFbzbp_zwhIubxjeQpa2JkfutdPOfmzU_6BhUyrYlOUvFAaw4cXZR0bdQVnW9lgDEESn6I6dBaaXH8gw9r7eD98jH8qRgnRszAYdUHVRBniRoRrm81HTv8Eu1CAK8HtglyJzN7UhKl2banQk-l47tl6wSle5eZVFwcGd3rcjLQaFaGZ8ZnUNVBs4HdwhwV6wuKcps-h6m3H07TMRBD-7cUBD1qmfRWS1HiADDiMamkH8LhCPMcNMpEK6c26eRl-0YdLdv9VskS-ooecanIB2PMhgRJV36-Rxds8oTwtwIhzeChexBp4qn0DfQ9sDgwog/file\n",
      "Reutilizando la conexión con uc776bd503b4554baf42e8e1444b.dl.dropboxusercontent.com:443.\n",
      "Petición HTTP enviada, esperando respuesta... 200 OK\n",
      "Longitud: 218189452 (208M) [application/zip]\n",
      "Grabando a: “data.zip”\n",
      "\n",
      "data.zip            100%[===================>] 208,08M  9,69MB/s    en 21s     \n",
      "\n",
      "2023-05-02 18:22:21 (9,72 MB/s) - “data.zip” guardado [218189452/218189452]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://www.dropbox.com/s/p3vd3plcbu9sf1o/data.zip?dl=0 -O data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  data.zip\n",
      "  inflating: data/ecg_tracings.hdf5  \n",
      "replace data/README.md? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n"
     ]
    }
   ],
   "source": [
    "!unzip data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tensorflow\n",
      "Version: 1.14.0\n",
      "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
      "Home-page: https://www.tensorflow.org/\n",
      "Author: Google Inc.\n",
      "Author-email: packages@tensorflow.org\n",
      "License: Apache 2.0\n",
      "Location: /home/tfg_luis_2223/.local/lib/python3.7/site-packages\n",
      "Requires: google-pasta, astor, gast, keras-preprocessing, six, protobuf, wheel, keras-applications, absl-py, tensorboard, wrapt, grpcio, numpy, termcolor, tensorflow-estimator\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip3 show tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python: can't open file 'install': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!python install -U pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# installing zipimport hook\n",
      "import zipimport # builtin\n",
      "# installed zipimport hook\n",
      "# /usr/lib/python2.7/site.pyc matches /usr/lib/python2.7/site.py\n",
      "import site # precompiled from /usr/lib/python2.7/site.pyc\n",
      "# /usr/lib/python2.7/os.pyc matches /usr/lib/python2.7/os.py\n",
      "import os # precompiled from /usr/lib/python2.7/os.pyc\n",
      "import errno # builtin\n",
      "import posix # builtin\n",
      "# /usr/lib/python2.7/posixpath.pyc matches /usr/lib/python2.7/posixpath.py\n",
      "import posixpath # precompiled from /usr/lib/python2.7/posixpath.pyc\n",
      "# /usr/lib/python2.7/stat.pyc matches /usr/lib/python2.7/stat.py\n",
      "import stat # precompiled from /usr/lib/python2.7/stat.pyc\n",
      "# /usr/lib/python2.7/genericpath.pyc matches /usr/lib/python2.7/genericpath.py\n",
      "import genericpath # precompiled from /usr/lib/python2.7/genericpath.pyc\n",
      "# /usr/lib/python2.7/warnings.pyc matches /usr/lib/python2.7/warnings.py\n",
      "import warnings # precompiled from /usr/lib/python2.7/warnings.pyc\n",
      "# /usr/lib/python2.7/linecache.pyc matches /usr/lib/python2.7/linecache.py\n",
      "import linecache # precompiled from /usr/lib/python2.7/linecache.pyc\n",
      "# /usr/lib/python2.7/types.pyc matches /usr/lib/python2.7/types.py\n",
      "import types # precompiled from /usr/lib/python2.7/types.pyc\n",
      "# /usr/lib/python2.7/UserDict.pyc matches /usr/lib/python2.7/UserDict.py\n",
      "import UserDict # precompiled from /usr/lib/python2.7/UserDict.pyc\n",
      "# /usr/lib/python2.7/_abcoll.pyc matches /usr/lib/python2.7/_abcoll.py\n",
      "import _abcoll # precompiled from /usr/lib/python2.7/_abcoll.pyc\n",
      "# /usr/lib/python2.7/abc.pyc matches /usr/lib/python2.7/abc.py\n",
      "import abc # precompiled from /usr/lib/python2.7/abc.pyc\n",
      "# /usr/lib/python2.7/_weakrefset.pyc matches /usr/lib/python2.7/_weakrefset.py\n",
      "import _weakrefset # precompiled from /usr/lib/python2.7/_weakrefset.pyc\n",
      "import _weakref # builtin\n",
      "# /usr/lib/python2.7/copy_reg.pyc matches /usr/lib/python2.7/copy_reg.py\n",
      "import copy_reg # precompiled from /usr/lib/python2.7/copy_reg.pyc\n",
      "# /usr/lib/python2.7/traceback.pyc matches /usr/lib/python2.7/traceback.py\n",
      "import traceback # precompiled from /usr/lib/python2.7/traceback.pyc\n",
      "# /usr/lib/python2.7/sysconfig.pyc matches /usr/lib/python2.7/sysconfig.py\n",
      "import sysconfig # precompiled from /usr/lib/python2.7/sysconfig.pyc\n",
      "# /usr/lib/python2.7/re.pyc matches /usr/lib/python2.7/re.py\n",
      "import re # precompiled from /usr/lib/python2.7/re.pyc\n",
      "# /usr/lib/python2.7/sre_compile.pyc matches /usr/lib/python2.7/sre_compile.py\n",
      "import sre_compile # precompiled from /usr/lib/python2.7/sre_compile.pyc\n",
      "import _sre # builtin\n",
      "# /usr/lib/python2.7/sre_parse.pyc matches /usr/lib/python2.7/sre_parse.py\n",
      "import sre_parse # precompiled from /usr/lib/python2.7/sre_parse.pyc\n",
      "# /usr/lib/python2.7/sre_constants.pyc matches /usr/lib/python2.7/sre_constants.py\n",
      "import sre_constants # precompiled from /usr/lib/python2.7/sre_constants.pyc\n",
      "import _locale # builtin\n",
      "# /usr/lib/python2.7/_sysconfigdata.pyc matches /usr/lib/python2.7/_sysconfigdata.py\n",
      "import _sysconfigdata # precompiled from /usr/lib/python2.7/_sysconfigdata.pyc\n",
      "# /usr/lib/python2.7/plat-x86_64-linux-gnu/_sysconfigdata_nd.pyc matches /usr/lib/python2.7/plat-x86_64-linux-gnu/_sysconfigdata_nd.py\n",
      "import _sysconfigdata_nd # precompiled from /usr/lib/python2.7/plat-x86_64-linux-gnu/_sysconfigdata_nd.pyc\n",
      "# /usr/lib/python2.7/sitecustomize.pyc matches /usr/lib/python2.7/sitecustomize.py\n",
      "import sitecustomize # precompiled from /usr/lib/python2.7/sitecustomize.pyc\n",
      "import encodings # directory /usr/lib/python2.7/encodings\n",
      "# /usr/lib/python2.7/encodings/__init__.pyc matches /usr/lib/python2.7/encodings/__init__.py\n",
      "import encodings # precompiled from /usr/lib/python2.7/encodings/__init__.pyc\n",
      "# /usr/lib/python2.7/codecs.pyc matches /usr/lib/python2.7/codecs.py\n",
      "import codecs # precompiled from /usr/lib/python2.7/codecs.pyc\n",
      "import _codecs # builtin\n",
      "# /usr/lib/python2.7/encodings/aliases.pyc matches /usr/lib/python2.7/encodings/aliases.py\n",
      "import encodings.aliases # precompiled from /usr/lib/python2.7/encodings/aliases.pyc\n",
      "# /usr/lib/python2.7/encodings/utf_8.pyc matches /usr/lib/python2.7/encodings/utf_8.py\n",
      "import encodings.utf_8 # precompiled from /usr/lib/python2.7/encodings/utf_8.pyc\n",
      "Python 2.7.16 (default, Oct 10 2019, 22:02:15) \n",
      "[GCC 8.3.0] on linux2\n",
      "Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n",
      "dlopen(\"/usr/lib/python2.7/lib-dynload/readline.x86_64-linux-gnu.so\", 2);\n",
      "import readline # dynamically loaded from /usr/lib/python2.7/lib-dynload/readline.x86_64-linux-gnu.so\n",
      ">>> \n",
      "Traceback (most recent call last):\n",
      "  File \"<stdin>\", line 1, in <module>\n",
      "KeyboardInterrupt\n",
      ">>> "
     ]
    }
   ],
   "source": [
    "!python -v"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## crear hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data/val.hdf5'\n",
    "f = h5py.File(filename, 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'CasosNumpy'\n",
    "df = pd.read_csv(\"data/annotations/val.csv\")\n",
    "group_name = 'tracings'\n",
    "shape = (len(df['id'].values),4096,12)\n",
    "dset = f.create_dataset(group_name,shape=shape)\n",
    "\n",
    "count = 0\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if(file_name[:5] in df['id'].values):\n",
    "        if file_name.endswith('.npy'):\n",
    "            # Cargar el archivo numpy\n",
    "            arr = np.load(os.path.join(folder_path, file_name))[:,:4096]\n",
    "            if arr.shape != (12, 4096):\n",
    "                new_arr = np.zeros((12, 4096))\n",
    "                new_arr[:arr.shape[0], :arr.shape[1]] = arr\n",
    "                arr = new_arr\n",
    "            #arr = tf.convert_to_tensor(arr, dtype=tf.float32)\n",
    "            dset[count, :, :] = arr.transpose()\n",
    "            count+=1\n",
    "            \n",
    "# Guardar el arreglo numpy en el grupo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modificar val.csv a como lo tiene antonio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/annotations/train.csv\")\n",
    "df = df.drop(['id','age','sex','r_count','length'],axis=1)\n",
    "df.to_csv(\"data/annotations/train_CPSC.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to open file (unable to open file: name = 'datasets/pred.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15220\\1952910778.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m\"datasets/pred.hdf5\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tracings'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[0;32m    565\u001b[0m                                  \u001b[0mfs_persist\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfs_persist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfs_threshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfs_threshold\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m                                  fs_page_size=fs_page_size)\n\u001b[1;32m--> 567\u001b[1;33m                 \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    568\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    229\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mflags\u001b[0m \u001b[1;33m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 231\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    232\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'r+'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to open file (unable to open file: name = 'datasets/pred.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "args= \"datasets/pred.hdf5\"\n",
    "with h5py.File(args, \"r\") as f:\n",
    "    x = np.array(f['tracings'])\n",
    "\n",
    "np.size(x[1])\n",
    "x.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!py train.py ./data/datos.hdf5 ./data/annotations/train_CPSC.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: train.py [-h] [--val_split VAL_SPLIT] [--dataset_name DATASET_NAME]\n",
      "                path_to_hdf5 path_to_csv\n",
      "\n",
      "Train neural network.\n",
      "\n",
      "positional arguments:\n",
      "  path_to_hdf5          path to hdf5 file containing tracings\n",
      "  path_to_csv           path to csv file containing annotations\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  --val_split VAL_SPLIT\n",
      "                        number between 0 and 1 determining how much of the\n",
      "                        data is to be used for validation. The remaining is\n",
      "                        used for validation. Default: 0.02\n",
      "  --dataset_name DATASET_NAME\n",
      "                        name of the hdf5 dataset containing tracings\n"
     ]
    }
   ],
   "source": [
    "!py train.py -h"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"predict.py\", line 28, in <module>\n",
      "    seq = ECGSequence(args.path_to_hdf5, args.dataset_name, batch_size=args.bs)\n",
      "  File \"e:\\automatic-ecg-diagnosis-private\\automatic-ecg-diagnosis\\datasets.py\", line 24, in __init__\n",
      "    self.f = h5py.File(path_to_hdf5, \"r\")\n",
      "  File \"C:\\Users\\quin-\\AppData\\Roaming\\Python\\Python37\\site-packages\\h5py\\_hl\\files.py\", line 567, in __init__\n",
      "    fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr)\n",
      "  File \"C:\\Users\\quin-\\AppData\\Roaming\\Python\\Python37\\site-packages\\h5py\\_hl\\files.py\", line 231, in make_fid\n",
      "    fid = h5f.open(name, flags, fapl=fapl)\n",
      "  File \"h5py\\_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py\\_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py\\h5f.pyx\", line 106, in h5py.h5f.open\n",
      "FileNotFoundError: [Errno 2] Unable to open file (unable to open file: name = './data/ecg.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n",
      "Exception ignored in: <function ECGSequence.__del__ at 0x000001F7FB41A4C8>\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\automatic-ecg-diagnosis-private\\automatic-ecg-diagnosis\\datasets.py\", line 48, in __del__\n",
      "    self.f.close()\n",
      "AttributeError: 'ECGSequence' object has no attribute 'f'\n"
     ]
    }
   ],
   "source": [
    "PFOLDER=\"./dnn_predicts\"\n",
    "DFOLDER=\"./data\" #Nos hemos cambiado al directorio de automatic-ecg-diagnosis\n",
    "\n",
    "!python predict.py $DFOLDER/ecg.hdf5 model.hdf5 --output_file $PFOLDER/ecg_tracings.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PFOLDER=\"./dnn_predicts\"\n",
    "DFOLDER=\"./data\" #Nos hemos cambiado al directorio de automatic-ecg-diagnosis\n",
    "\n",
    "!python predict.py $DFOLDER/ecg_tracings2.hdf5 model.hdf5 --output_file $PFOLDER/ecg_tracings.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1/1 [==============================] - ETA: 0s\n",
      "1/1 [==============================] - 1s 611ms/step\n",
      "Output predictions saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-11 17:05:27.299509: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "PFOLDER=\"./dnn_predicts\"\n",
    "DFOLDER=\"./data\" #Nos hemos cambiado al directorio de automatic-ecg-diagnosis\n",
    "\n",
    "!python predict.py $DFOLDER/pred.hdf5 final_model.hdf5 --output_file $PFOLDER/pred.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: predict.py [-h] [--dataset_name DATASET_NAME]\n",
      "                  [--output_file OUTPUT_FILE] [-bs BS]\n",
      "                  path_to_hdf5 path_to_model\n",
      "\n",
      "Get performance on test set from hdf5\n",
      "\n",
      "positional arguments:\n",
      "  path_to_hdf5          path to hdf5 file containing tracings\n",
      "  path_to_model         file containing training model.\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  --dataset_name DATASET_NAME\n",
      "                        name of the hdf5 dataset containing tracings\n",
      "  --output_file OUTPUT_FILE\n",
      "                        output csv file.\n",
      "  -bs BS                Batch size.\n"
     ]
    }
   ],
   "source": [
    "!python predict.py -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.5101798e-03 1.6017100e-05 6.6078037e-01 5.1851600e-04 2.2911260e-07]\n",
      "[22  0  0  0  1  0  0]\n"
     ]
    }
   ],
   "source": [
    "pred = np.load('dnn_predicts/ecg_tracings.npy')\n",
    "csv = pd.read_csv('data/annotations/dnn.csv')\n",
    "pos = 22\n",
    "print(pred[pos,1:])\n",
    "print(csv.values[pos])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = np.load('dnn_predicts/model_pred.npy')\n",
    "pred[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.6429495e-09 9.9344963e-01 5.0510238e-03 7.9479541e-06 4.1719411e-02\n",
      " 2.9839315e-13 1.1956898e-03 2.2249950e-02 4.2172393e-18]\n",
      "['A3483' 75 0 0 1 0 0 1 0 0 0 0 19 5000]\n"
     ]
    }
   ],
   "source": [
    "pred = np.load('dnn_predicts/train.npy')\n",
    "csv = pd.read_csv('data/annotations/train.csv')\n",
    "pos = 0\n",
    "print(pred[pos,1:])\n",
    "print(csv.values[pos])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.7825001e-09 9.9343199e-01 5.0518359e-03 8.0328427e-06 4.1804649e-02\n",
      " 3.0411887e-13 1.2021037e-03 2.2318605e-02 4.3300473e-18]\n"
     ]
    }
   ],
   "source": [
    "pred = np.load('dnn_predicts/pred.npy')\n",
    "pos = 25\n",
    "print(pred[pos,1:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
